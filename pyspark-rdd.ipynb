{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"40aef8a8-60ff-438e-b76d-183360b4db02","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nprint(spark)\nrdd=spark.sparkContext.parallelize([1,2,3,4,56])\nprint(\"RDD count :\"+str(rdd.count()))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0845b3aa-3c7f-48f5-842e-a3916b4cc700","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["<pyspark.sql.session.SparkSession object at 0x7f6fc6f31400>\nRDD count :5\n"]}],"execution_count":0},{"cell_type":"code","source":["rdd = spark.sparkContext.emptyRDD\nprint(rdd)\nrdd2 = spark.sparkContext.parallelize([])\nprint(rdd2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4ab1bd77-ab73-4587-baf1-6fac4a38be6d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["<bound method SparkContext.emptyRDD of <SparkContext master=local[8] appName=Databricks Shell>>\nParallelCollectionRDD[212] at readRDDFromInputStream at PythonRDD.scala:435\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"697776b3-1557-462a-860e-98820dcc1440","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-rdd","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
